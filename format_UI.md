# GWAS SumStats Tools Online Interface 
____
This guide describes how to use the [GWAS SumStats Tools Online Interface](https://ebispot.github.io/gwas-sumstat-format-was/). You can use this tool to either format your summary statistics files into the GWAS Catalog standard format, as specified by the [gwas-ssf](https://github.com/EBISPOT/gwas-summary-statistics-standard) schema, or to validate whether your files adhere to this standard format.

>[!ATTENTION|style:callout]
>This interface requires a **chromium browser** (Google Chrome, Microsoft Edge) that supports the [File System Access API](https://developer.chrome.com/docs/capabilities/web-apis/file-system-access).

>[!ATTENTION|style:callout]
>Please note that this interface works with **a single file only** and has a file size limitation of **2 GB**. 

## Overview

Users can select a file from their local folder for formatting (Steps 1 to 4) or validation (Step 5) using this interface.

### Format
The format process involves three main steps:

1. Generate Configuration Template: Initially, a configuration template is generated from the input file. This template serves as a blueprint for configuring the formatting options.
2. Fill in the Template: In this step, users specify how they want the file to be formatted by filling in the template. The templates is creted in JSON format, which is optimal for compute cluster environments.
3. Apply Template to the File: The final step involves applying the filled-in template to the input file, resulting in a formatted output file according to the specified configurations.

The UI provides all the functionalities found in the CLI. Users can select an input file from their local directory by **first** clicking on the `Grant Permission` button, which allows the browser read and write access to a specific folder. **After** granting permission, click `Select Input File` to choose your input file from the authorized folder. The message `<your file> is selected` confirms that the file has been successfully selected.

For the configuration file, users have the following options:

1. Click the `Generate` button to create a configuration file based on the selected input file. The generated file will appear as a template in the text box under the `Configure` section. To further tailor the configuration file to better suit your needs, click on `Show Your Input Data` and/or `Show Example Data` to compare the differences and make necessary adjustments.
2. Copy and paste your own configuration file into the text box under the `Configure` section.
3. Select the appropriate analysis software from the `Analysis Software` dropdown menu if your data is generated by `REGENIE` or `BOLT-LMM`. Support for `METAL` and `SNPtest` will be available soon.

Once you are satisfied with your configuration, you can opt to click the `Test` Button. This action applies the configuration to the first **FIVE** rows of your selected input file and generates a formatted preview output, which will be displayed under the `Your Output` section.This approach can save a considerable amount of time, especially if your input file is large.

Once you click the `Apply Button`, you will have the option to choose the destination and name for your formatted output file. This selection will overwrite the `outFileSuffix` specified in your configuration. After setting these options, the configuration will be applied to the entire input file, and the formatted output will be generated as a file.

### Validate
This online validation tool is designed to ensure that selected summary statistics files comply with the [gwas-ssf](https://github.com/EBISPOT/gwas-summary-statistics-standard) schema as defined by the GWAS Catalog. Unlike the CLI validation, this tool does not allow forcing acceptance of zero P-values or adjustments based on the minimum number of rows. The minimum required number of rows is set at 100,000 to pass the validation.

The UI validation function operates independently from the formatting function and can be used separately. If you haven't yet accessed the formatting section, start by scrolling to the top of the page and clicking the `Grant Permission` button. After granting permission, click the `Select to Validate` button to choose the file you want to validate. This can be any file or a file previously formatted through the formatting function. Once the file is successfully selected, a confirmation message, `<your file> is selected for validation`, will appear. Next, click the `Validate Selected File` button, and the validation results will be displayed in the box below.


## How to Edit the Configuration
### JSON template file
The JSON file defines configurations for formatting a summary statistics file. It includes options for output file settings and column-specific formatting operations. Users can customize field separators, column splitting, renaming, finding and replacing values, and more based on their requirements.

On the UI, configurations are displayed in a text box that allows users to easily customize settings directly, eliminating the need to open and edit JSON files.

<details>
<summary>Here is an example of the JSON configuration template</summary>

```json
{
    "fileConfig": {
        "outFileSuffix": null,
        "convertNegLog10Pvalue": false,
        "fieldSeparator": " ",
        "removeComments": null,
    },
    "columnConfig": {
        "split": [
            {
                "field": "SNP",
                "separator": null,
                "capture": null,
                "new_field": null,
                "include_original": null
            },
            {
                "field": "A1",
                "separator": null,
                "capture": null,
                "new_field": null,
                "include_original": null
            },
            {
                "field": "A2",
                "separator": null,
                "capture": null,
                "new_field": null,
                "include_original": null
            },
            {
                "field": "freq",
                "separator": null,
                "capture": null,
                "new_field": null,
                "include_original": null
            },
            {
                "field": "b",
                "separator": null,
                "capture": null,
                "new_field": null,
                "include_original": null
            },
            {
                "field": "se",
                "separator": null,
                "capture": null,
                "new_field": null,
                "include_original": null
            },
            {
                "field": "p",
                "separator": null,
                "capture": null,
                "new_field": null,
                "include_original": null
            },
            {
                "field": "N_cases",
                "separator": null,
                "capture": null,
                "new_field": null,
                "include_original": null
            },
            {
                "field": "N_controls",
                "separator": null,
                "capture": null,
                "new_field": null,
                "include_original": null
            }
        ],
        "edit": [
            {
                "field": "SNP",
                "rename": "variant_id",
                "find": null,
                "replace": null,
                "extract": null
            },
            {
                "field": "",
                "rename": "",
                "find": null,
                "replace": null,
                "extract": null
            },
            {
                "field": "A1",
                "rename": "effect_allele",
                "find": null,
                "replace": null,
                "extract": null
            },
            {
                "field": "A2",
                "rename": "other_allele",
                "find": null,
                "replace": null,
                "extract": null
            },
            {
                "field": "freq",
                "rename": "effect_allele_frequency",
                "find": null,
                "replace": null,
                "extract": null
            },
            {
                "field": "b",
                "rename": "beta",
                "find": null,
                "replace": null,
                "extract": null
            },
            {
                "field": "se",
                "rename": "standard_error",
                "find": null,
                "replace": null,
                "extract": null
            },
            {
                "field": "p",
                "rename": "p_value",
                "find": null,
                "replace": null,
                "extract": null
            },
            {
                "field": "N_cases",
                "rename": "n_cas",
                "find": null,
                "replace": null,
                "extract": null
            },
            {
                "field": "N_controls",
                "rename": "n_con",
                "find": null,
                "replace": null,
                "extract": null
            }
        ]
    }
}
```
</details>

The JSON config file comprises two primary sections: `fileConfig` and `columnConfig`. The columnConfig section further encompasses two subsections: `split` and `edit`. The `fileConfig` settings are applied to the input file first, followed by modifications from the `split` and the `edit` subsections, which represent the final changes to the input files.

#### `fileConfig` Section:
  - `outFileSuffix`: Specifies the suffix for the output file. It is currently set to null.
  - `convertNegLog10Pvalue`: Specifies whether to convert negative log10 p-values. It is set to false defautly
  - `fieldSeparator`: Defines the field separator for the output file. It is same to the `--delimiter` in the command line. If not specified, we can automatically detect the delimiter as whitespace if your is *.txt file, or comma if your is *.csv file; or tab if your is *.tsv file. Otherwise, please specify the delimiter which can help to recognise the column correctly
  - `removeComments`: The `removeComments` field in the JSON config acts like the `--remove_comments` command-line option. Setting it to a character or string, like "#", removes lines starting with that character or string from the input file. For instance, `"removeComments": "#"` removes lines beginning with `#`, eliminating comments or metadata and ensuring a cleaner output.

#### `columnConfig` Section:
##### `split` Subsection:

This subsection specifies how to split certain columns in the input file.For each column, it contains:

  - `field`: Specifies the name of the column to be split.
  - `separator`: Defines the delimiter used to split th  column. New columns created from the split will be name  as specified in the `new_field`.
  - `capture`: Utilizes a regular expression to extrac  specific patterns from the field into multiple ne  columns. These resulting columns are named according t  the values specified in `new_field`.
  - `new_field`: Names the new fields created afte  splitting.
  - `include_original`: Determines whether to retain th  original column after the spliting. By default, th  original field is omitted after the operation.

      * <details>
        <summary>Separator example</summary>

        **Input**:
        | SNP | rsid | EA |
        |-----|-------|---------|
        | chr11:88249377 | rs11020170_T_C  | T   |
        | chr1:60320992 | rs116406626_A_G  | A   |
        | chr2:18069070 | rs763680312_T_C  | T   |
        | chr8:135908647 | rs11992603_A_G  | A   |

        **JSON config**:
        ```json
        "field": "SNP",
        "separator": ":",
        "capture": null,
        "new_field": ["chromosome","base_pair_location"],
        "include_original": true
        ```
        **Output**:
        | SNP | rsid | EA |chromosome|base_pair_location|
        |-----|-------|---------|----|------------------|
        | chr11:88249377 | rs11020170_T_C  | T   |chr11 |88249377 |
        | chr1:60320992 | rs116406626_A_G  | A   |chr1| 60320992 |
        | chr2:18069070 | rs763680312_T_C  | T   |chr2 |18069070 |
        | chr8:135908647 | rs11992603_A_G  | A   |chr8| 135908647 |
        </details>
      * <details>
        <summary>Capture example</summary>

        **Input**:
        | SNP | rsid | EA |chromosome|base_pair_location|
        |-----|-------|---------|----|------------------|
        | chr11:88249377 | rs11020170_T_C  | T   |chr11 |88249377 |
        | chr1:60320992 | rs116406626_A_G  | A   |chr1| 60320992 |
        | chr2:18069070 | rs763680312_T_C  | T   |chr2 |18069070 |
        | chr8:135908647 | rs11992603_A_G  | A   |chr8| 135908647 |

        **JSON config**:
        ```json
        "field": "rsid",
        "separator": null,
        "capture": "(rs[0-9]+)_([A,T,C,G])_([A,T,C,G])",
        "new_field": ["rsid","effect_allele","other_allele"],
        "include_original": false
        ```
        **Output**:
        | SNP | EA |chromosome|base_pair_location| rsid | effect_allele| other_allele |
        |-----|---------|----|------------------|-----|-----|----|
        | chr11:88249377 |T   |chr11 |88249377 |rs11020170 | T | C  |
        | chr1:60320992 |A   |chr1| 60320992 |rs116406626 |A | G|
        | chr2:18069070 |T   |chr2 |18069070 |rs763680312| T |C |
        | chr8:135908647 |A   |chr8| 135908647 |rs11992603 |A |G |

        >[!TIP|style:callout]
        > If you're new to regex, [Regex101](https://regex101.com/) is a highly recommended online tool for testing and debugging regular expressions. It offers detailed explanations of each component of your regex and tests your patterns against sample texts for easy understanding. Additionally, there are numerous [regex cheat sheet](https://cheatography.com/davechild/cheat-sheets/regular-expressions/) available online that provide a handy quick-start guide to familiarize yourself with the basics.
        </details>

##### `edit` Subsection:

This subsection specifies editing operations to be performed on certain columns.Each entry contains:
   - `field`: The name of the column to edit.
   - `rename`: Specifies the new name for the column.
   - `find`: Specifies a pattern to find within the column.
   - `replace`: Specifies a pattern to replace within the    column.
   - `extract`: Specifies a pattern to extract from the column.

      * <details>
        <summary>Find and replace example</summary>

        **Input**:
        | SNP | EA |chromosome|base_pair_locatiorsid | effect_allele|other_allele |
        |-----|----|---------|----------------------|-------------|------------|
        | chr11:88249377 |T   |chr11 |88249377   rs11020170 |     T | C  |
        | chr1:60320992 |A   |CHR1| 60320992   rs116406626 |    A | G|
        | chr2:18069070 |T   |chr2 |18069070   rs763680312|     T |C |
        | chr8:135908647 |A   |CHR8| 135908647    rs11992603 |    A |G |
        
        **JSON config**:
         ```json
        "field": "chromosome",
        "rename": "chromosome",
        "find": "chr|CHR",
        "replace": "",
        "extract": null
         ```
        
        **Output**:
        | SNP | EA |chromosome|base_pair_location| rsid|effect_allele| other_allele |
        |-----|---------|----|------------------|---------|----|------|
        | chr11:88249377 |T   |11 |88249377| rs11020170 |     T | C  |
        | chr1:60320992 |A   |1| 60320992 |rs116406626|A |     G|
        | chr2:18069070 |T   |2 |18069070 |rs763680312 |T |    C |
        | chr8:135908647 |A   |8| 135908647 |rs11992603 |A |    G |
        
        
        When utilizing the find and replace function, please note that it will modify values within the columns but not within the headers. For instance, if you attempt to replace `chr` in the column headers, the term in the header `chromosome` will remain unchanged. Please use the `rename` function to change the header.

        >[!NOTE|style:callout]
        > Please use "find and replace" together. To remove any character, enter `""` (an empty string) in the replace field, rather than leaving it as `null`.

        </details>

    
      * <details>
        <summary>Extract example</summary>

        **Input**:
        | chromosome| base_pair_location | rsid | effect_allele|other_allele |
        |-----|-------|-------------|-------------|------|
        | 11| 88249377 | rs11020170_T_C  | T   | C|
        | 1| 60320992 | rs116406626_A_G  | A   | G|
        | 2| 18069070 | rs763680312_T_C  | T   | C|
        | 8|135908647 | rs11992603_A_G  | A   | G|
        
        **JSON config**:
         ```json
        "field": "rsid",
        "rename": "variant_id",
        "find": null,
        "replace": null,
        "extract": "rs"
         ```
        
        **Output**:
         | chromosome| base_pair_location | variant_id | effect_allele|other_allele |
        |-----|-------|-------------|-------------|------|
        | 11| 88249377 | rs11020170 | T   | C|
        | 1| 60320992 | rs116406626  | A   | G|
        | 2| 18069070 | rs763680312 | T   | C|
        | 8|135908647 | rs11992603  | A   | G|
        
        </details>

## Additional Functions
Beyond formatting the input file according to the configuration file, the format tool also applies several default settings to every summary statistic:

1. Reorder the mandatory columns in your dataset to match the GWAS-SSF specified sequence: 
```text
chromosome, base_pair_location, effect_allele, other_allele, effect (beta/odds ratio/hazard ratio), standard_error, effect_allele_frequency, pval (or negativelog10Pvalue). 
```
Arrange any additional columns in their original input order.
2. Filling Missing Fields: If any mandatory column is missing from the input file, the format tool will automatically add this column and populate all its values with `#NA`.
3. Convert NA Values: The tool converts any 'NA' or 'None' values with `#NA`, ensuring data consistency.

----
Copyright Â© EMBL-EBI 2024 | EMBL-EBI is an Outstation of the [European Molecular Biology Laboratory](https://www.embl.org/) | [Terms of use](https://www.ebi.ac.uk/about/terms-of-use) | [Data Preservation Statement](https://www.ebi.ac.uk/long-term-data-preservation)
